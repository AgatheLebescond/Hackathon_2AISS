# ğŸ§  Moteur de Recherche, RÃ©sumÃ© Automatique et Analyse d'Articles avec IA GÃ©nÃ©rative

---

## ğŸ“ Contexte pÃ©dagogique

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du **Hackathon 2 â€” Team Invader**, au sein d'une formation bootcamp.

Il combine les technologies de **recherche sÃ©mantique**, de **rÃ©sumÃ© automatique**, et dâ€™**extraction dâ€™articles web** pour fournir une application complÃ¨te, 100% locale.Nous avons pris comme exemple la petition contre l'abrogation de la loi Duplomb.

---

## ğŸŒŸ Objectifs pÃ©dagogiques

| Objectif                                    | CompÃ©tence dÃ©veloppÃ©e                    |
| ------------------------------------------- | ---------------------------------------- |
| Extraction de texte (PDF/DOCX/articles web) | Parsing multi-format, HTML, API          |
| Extraction des mÃ©tadonnÃ©es (date, image)    | Parsing HTML, traitement JSON NewsAPI    |
| Nettoyage et dÃ©coupage NLP                  | spaCy, segmentation linguistique         |
| Embedding vectoriel                         | Sentence-Transformers (MiniLM)           |
| Recherche vectorielle                       | FAISS + similaritÃ© cosine                |
| RÃ©sumÃ© gÃ©nÃ©ratif                            | DistilBART prÃ©-entraÃ®nÃ©                  |
| Question-rÃ©ponse contextuelle               | Vectorisation + top-k context chunks     |
| RÃ©sumÃ© guidÃ© via prompt thÃ©matique          | Prompt engineering (mobilisation/climat) |
               |
| Interface interactive                       | Streamlit                                |

---

## âš™ï¸ FonctionnalitÃ©s principales

- ğŸ“„ Upload de documents PDF ou DOCX
- ğŸŒ Extraction automatique dâ€™articles via URL
- ğŸ”— **Connexion Ã  NewsAPI pour tÃ©lÃ©charger le contenu complet dâ€™un article Ã  partir de son URL**
- ğŸ–¼ï¸ **RÃ©cupÃ©ration automatique des mÃ©tadonnÃ©es de lâ€™article** : titre, auteur, date de publication, **URL de lâ€™image dâ€™en-tÃªte**, nom du journal
- â“ Questions en langage naturel (question answering vectoriel)
- ğŸ” Recherche vectorielle top-k contextuelle (passages les plus pertinents)
- ğŸ“ RÃ©sumÃ© gÃ©nÃ©rÃ© automatiquement via modÃ¨le Transformer
- ğŸ§½ RÃ©sumÃ© guidÃ© par **prompt thÃ©matique** : climat, mobilisation citoyenne, loi Duplomb
- ğŸ“¤ Export des rÃ©sultats : `.txt`, `.pdf`, `.png`
---

## ğŸ” Pipeline IA complet

```text
1. Upload dâ€™un fichier PDF/DOCX ou saisie dâ€™une URL
2. Extraction du texte (pdfplumber / NewsAPI / HTML parser)
3. Extraction des mÃ©tadonnÃ©es : titre, date, image, journal (si disponible)
4. Nettoyage et dÃ©coupage (spaCy)
5. Vectorisation sÃ©mantique (MiniLM)
6. Indexation locale via FAISS
7. Saisie dâ€™une question libre â†’ recherche contextuelle top-k
8. Choix entre deux boutons :
   - ğŸ“„ RÃ©sumÃ© classique (neutre)
   - ğŸŒ RÃ©sumÃ© thÃ©matique (mobilisation citoyenne, climat, loi Duplomb)
9. Affichage dynamique via Streamlit (texte + mÃ©tadonnÃ©es + image + nuage)
10. Export des rÃ©sultats : `.txt`, `.pdf`, `.png`
```

---

## ğŸ” IntÃ©gration de NewsAPI

Le projet intÃ¨gre [**NewsAPI**](https://newsapi.org/) pour extraire le contenu dâ€™articles dâ€™actualitÃ© directement Ã  partir dâ€™une URL.

### âš™ï¸ PrÃ©requis :

Un fichier `.env.example` est fourni pour aider Ã  la configuration locale :

```env
# .env.example
NEWS_API_KEY=your_api_key_here
```

â¡ï¸ **Ã€ faire** :

- Copier `.env.example` â†’ `.env`
- Remplacer `your_api_key_here` par votre vraie clÃ© NewsAPI

1. CrÃ©er un compte gratuit sur [https://newsapi.org/](https://newsapi.org/)
2. RÃ©cupÃ©rer une clÃ© dâ€™API personnelle
3. La stocker dans un fichier `.env` (ou comme variable dâ€™environnement) :

```
NEWS_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxx
```


La clÃ© est ensuite chargÃ©e dans le code via :

```python
import os
NEWS_API_KEY = os.getenv("NEWS_API_KEY")
```

Le systÃ¨me rÃ©cupÃ¨re automatiquement les **mÃ©tadonnÃ©es** suivantes pour chaque article extrait :

- ğŸ•’ Date et heure de publication
- ğŸ–¼ï¸ Image dâ€™en-tÃªte (URL)
- âœï¸ Auteur, nom du **journal ou magazine** (source), si disponibles

---

## ğŸ–¥ï¸ Interface utilisateur (Streamlit)

- ğŸ“ TÃ©lÃ©versement de fichiers PDF/DOCX
- ğŸŒ Collage dâ€™une **URL dâ€™article dâ€™actualitÃ©** (via NewsAPI)
- ğŸ•’ Affichage de la **date de publication** de lâ€™article
- ğŸ–¼ï¸ Affichage de lâ€™**image dâ€™illustration** (si prÃ©sente)
- ğŸ“° Affichage du **nom du journal ou mÃ©dia**
- â“ Saisie dâ€™une question libre
- ğŸ” Recherche sÃ©mantique des passages pertinents
- ğŸ“ Deux types de rÃ©sumÃ©s gÃ©nÃ©rÃ©s :
  - ğŸ“„ RÃ©sumÃ© classique (neutre)
  - ğŸŒ RÃ©sumÃ© thÃ©matique (mobilisation citoyenne, climat, loi Duplomb)
- ğŸ“¥ Boutons dâ€™export : rÃ©sumÃ© (.txt), visuel (.png), log

---

## ğŸ“ Arborescence du projet

```
PSTB_ai_doc_search/
â”œâ”€â”€ automation/
â”‚   â””â”€â”€ watcher.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ outputs/
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ extractor.py
â”‚   â”œâ”€â”€ newsapi_fetcher.py
â”‚   â”œâ”€â”€ article_to_pdf.py
â”‚   â”œâ”€â”€ cleaner.py
â”‚   â””â”€â”€ processing/
â”‚       â”œâ”€â”€ splitter.py
â”‚       â”œâ”€â”€ embedder.py
â”‚       â”œâ”€â”€ indexer.py
â”‚       â”œâ”€â”€ summarizer.py
â”‚       â”œâ”€â”€ query_article.py
â”‚       â”œâ”€â”€ sentiment_analyzer.py
â”‚       â””â”€â”€ wordcloud_generator.py
â”œâ”€â”€ visualisation/
â”‚   â””â”€â”€ wordclouds/
â”œâ”€â”€ frontend.py
â”œâ”€â”€ compress.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## âœ… RÃ©sultats obtenus

- ğŸ” Traitement automatisÃ© de fichiers et dâ€™articles web
- ğŸ§  RÃ©sumÃ©s gÃ©nÃ©rÃ©s localement en deux modes : classique ou thÃ©matique
- ğŸ” Recherche sÃ©mantique top-k des rÃ©ponses contextuelles
- ğŸ“¦ Projet packagÃ©, prÃªt Ã  Ãªtre exÃ©cutÃ© localement

