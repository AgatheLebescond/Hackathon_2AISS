import os
import streamlit as st

from ingestion.extractor import extract_text_from_file
from ingestion.cleaner import clean_text
from ingestion.processing.splitter import split_text
from ingestion.processing.embedder import embed_chunks
from ingestion.processing.indexer import build_faiss_index, index_chunks
from ingestion.processing.summarizer import generate_summary  # , generate_thematic_summary
from ingestion.newsapi_fetcher import fetch_article_from_url

# === Configuration Streamlit
st.set_page_config(page_title="AI RÃ©sumeur", layout="wide")
st.title("ğŸ§  RÃ©sumeur intelligent d'articles & PDF")

# ---------- Session state ----------
defaults = {
    "raw_text": None,
    "cleaned": None,
    "chunks": None,
    "index": None,
    "summary": None,
    "metadata": {},
    "doc_id": None,
    "auto_summarize": True,  # NEW: toggle to auto-generate summary after extraction
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# === Helpers ===
def save_uploaded_file(uploaded_file):
    filepath = os.path.join("data/uploads", uploaded_file.name)
    with open(filepath, "wb") as f:
        f.write(uploaded_file.read())
    return filepath

def process_text_pipeline(raw_text):
    cleaned = clean_text(raw_text)
    chunks = split_text(cleaned)
    embeddings = embed_chunks(chunks)
    embedding_dim = embeddings.shape[1]
    index = build_faiss_index(embedding_dim)
    index_chunks(index, embeddings)
    return cleaned, chunks, index

def run_pipeline_and_store(text, doc_id=None, metadata=None):
    cleaned, chunks, index = process_text_pipeline(text)
    st.session_state.raw_text = text
    st.session_state.cleaned = cleaned
    st.session_state.chunks = chunks
    st.session_state.index = index
    st.session_state.doc_id = doc_id or "document"
    st.session_state.metadata = metadata or {}

def display_summary_section(chunks, thematic=False, theme=None):
    """Affichage dâ€™un rÃ©sumÃ© gÃ©nÃ©rÃ© automatiquement"""
    with st.spinner("GÃ©nÃ©ration du rÃ©sumÃ©..."):
        if thematic and theme:
            # summary = generate_thematic_summary(chunks, theme=theme)
            summary = generate_summary(chunks)
            st.subheader(f"ğŸŒ RÃ©sumÃ© thÃ©matique : {theme}")
        else:
            summary = generate_summary(chunks)
            st.subheader("ğŸ“ RÃ©sumÃ© gÃ©nÃ©rÃ©")
    st.success(summary)
    return summary

def display_metadata(metadata):
    st.subheader("â„¹ï¸ MÃ©tadonnÃ©es de lâ€™article")
    st.write(f"ğŸ“° Source : **{metadata.get('source', 'N/A')}**")
    st.write(f"ğŸ•“ Date : {metadata.get('publishedAt', 'N/A')}")
    if metadata.get("image_url"):
        st.image(metadata["image_url"], caption="Image dâ€™illustration")

# === Interface principale ===
tab1, tab2, tab3 = st.tabs(["ğŸ“„ Fichier PDF/DOCX", "ğŸŒ Article en ligne", "ğŸ§¾ RÃ©sultats"])

with tab1:
    st.checkbox(
        "GÃ©nÃ©rer automatiquement un rÃ©sumÃ© aprÃ¨s l'extraction",
        key="auto_summarize",
        help="Si cochÃ©, le rÃ©sumÃ© est produit dÃ¨s que l'article/le fichier est chargÃ©."
    )
    uploaded_file = st.file_uploader("TÃ©lÃ©verser un fichier", type=["pdf", "docx"], key="file_uploader")
    if uploaded_file:
        doc_id = os.path.splitext(uploaded_file.name)[0]
        filepath = save_uploaded_file(uploaded_file)
        text = extract_text_from_file(filepath)
        run_pipeline_and_store(text, doc_id=doc_id, metadata={})
        st.success("Fichier chargÃ©.")
        if st.session_state.auto_summarize and st.session_state.chunks:
            st.session_state.summary = display_summary_section(st.session_state.chunks)

with tab2:
    url = st.text_input("Coller lâ€™URL dâ€™un article dâ€™actualitÃ©", key="url_input")
    if st.button("Extraire lâ€™article depuis lâ€™URL", key="fetch_url") and url:
        try:
            st.markdown("Fetcherâ€¦")
            article_data = fetch_article_from_url(url, api_token="00d1111a7e584642bf066fb39c6746b8")
            text = article_data.get('text', '') or ''
            meta = article_data.get('metadata', {}) or {}
            doc_id = meta.get('title', 'article')
            if not text.strip():
                st.warning("Aucun texte nâ€™a Ã©tÃ© extrait depuis lâ€™URL.")
            run_pipeline_and_store(text, doc_id=doc_id, metadata=meta)
            st.success("Article extrait.")
            if st.session_state.auto_summarize and st.session_state.chunks:
                st.session_state.summary = display_summary_section(st.session_state.chunks)
        except Exception as e:
            st.error(f"Erreur lors de lâ€™extraction : {e}")

    # Boutons de gÃ©nÃ©ration manuelle
    if st.session_state.chunks:
        st.markdown("---")
        st.markdown("## ğŸ¯ Choisir le type de rÃ©sumÃ©")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“„ RÃ©sumÃ© classique", key="classic_summary"):
                st.session_state.summary = display_summary_section(st.session_state.chunks)
        with col2:
            theme = st.selectbox(
                "ğŸŒ Choisir un thÃ¨me pour le rÃ©sumÃ© thÃ©matique",
                ["climat", "mobilisation citoyenne", "loi Duplomb"],
                key="theme_select"
            )
            if st.button("ğŸŒ RÃ©sumÃ© thÃ©matique", key="thematic_summary"):
                st.session_state.summary = display_summary_section(
                    st.session_state.chunks, thematic=True, theme=theme
                )

with tab3:
    st.markdown("## ğŸ§¾ RÃ©sultats")
    # RÃ©sumÃ© (toujours affichÃ© s'il existe)
    if st.session_state.summary:
        st.subheader("ğŸ“ RÃ©sumÃ©")
        st.text_area("RÃ©sumÃ© gÃ©nÃ©rÃ©", st.session_state.summary, height=280)
        st.download_button(
            "ğŸ’¾ TÃ©lÃ©charger le rÃ©sumÃ© (.txt)",
            st.session_state.summary,
            file_name=f"{st.session_state.doc_id or 'document'}_resume.txt",
            key="download_summary"
        )
    else:
        st.info("Aucun rÃ©sumÃ© pour lâ€™instant. Importez un contenu et gÃ©nÃ©rez un rÃ©sumÃ©.")

    # MÃ©tadonnÃ©es (si disponibles)
    if st.session_state.metadata:
        st.markdown("---")
        display_metadata(st.session_state.metadata)

    # Diagnostics utiles
    if st.session_state.cleaned or st.session_state.chunks:
        st.markdown("---")
        st.subheader("ğŸ” Diagnostics")
        c1, c2, c3 = st.columns(3)
        if st.session_state.cleaned:
            c1.metric("Mots (texte nettoyÃ©)", len(st.session_state.cleaned.split()))
        if st.session_state.chunks:
            c2.metric("Nombre de chunks", len(st.session_state.chunks))
            # aperÃ§u du 1er chunk
            with st.expander("AperÃ§u du 1er chunk"):
                st.code(st.session_state.chunks[0][:1000])
        if st.session_state.index:
            c3.write("Index FAISS : **OK**")

# Message dâ€™accueil si rien encore
if not (st.session_state.raw_text or st.session_state.chunks or st.session_state.summary):
    st.info("TÃ©lÃ©verse un fichier ou entre une URL pour commencer.")
